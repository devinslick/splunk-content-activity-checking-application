# Search macros for CACA - Content Activity Checking Application
# Version: 1.0.0 - Comprehensive rewrite with configurable thresholds

#####################
# Settings & Configuration Macros
#####################

# Load all CACA settings from lookup
[caca_load_settings]
definition = | inputlookup caca_settings \
| eval {setting_name}=setting_value \
| stats values(*) as * \
| fields - setting_name setting_value setting_description
iseval = 0

# Get a specific setting value
[caca_get_setting(1)]
args = setting_name
definition = | inputlookup caca_settings where setting_name="$setting_name$" \
| return $setting_value
iseval = 0

#####################
# Core Query Macros
#####################

# Get all metrics for a specific dashboard with time-series data
[get_dashboard_stats(1)]
args = dashboard_name
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.*" AND pretty_name="$dashboard_name$" BY pretty_name, metric_name, activity_type, app span=1h \
| eval metric_display=case(\
    metric_name=="dashboard.views", "Views",\
    metric_name=="dashboard.edits", "Edits",\
    metric_name=="dashboard.errors", "Errors",\
    metric_name=="dashboard.load_time", "Load Time (ms)",\
    1=1, metric_name) \
| fillnull value=0 metric_value
iseval = 0

# Get dashboard stats with configurable time range
[get_dashboard_stats_timerange(2)]
args = dashboard_name, timerange
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.*" AND pretty_name="$dashboard_name$" BY pretty_name, metric_name, activity_type, app span=1h \
| where _time >= relative_time(now(), "$timerange$") \
| eval metric_display=case(\
    metric_name=="dashboard.views", "Views",\
    metric_name=="dashboard.edits", "Edits",\
    metric_name=="dashboard.errors", "Errors",\
    metric_name=="dashboard.load_time", "Load Time (ms)",\
    1=1, metric_name) \
| stats sum(metric_value) as total_value by pretty_name, metric_display, metric_name \
| fillnull value=0 total_value
iseval = 0

# Get summary of all dashboards for the last 7 days
[get_all_dashboards_summary]
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.*" BY pretty_name, metric_name, app span=1d \
| where _time >= relative_time(now(), "-7d@d") \
| stats sum(metric_value) as total_value by pretty_name, metric_name, app \
| eval metric_type=case(\
    metric_name=="dashboard.views", "views_7d",\
    metric_name=="dashboard.edits", "edits_7d",\
    metric_name=="dashboard.errors", "errors_7d",\
    metric_name=="dashboard.load_time", "load_time_7d",\
    1=1, "other") \
| eval {metric_type}=total_value \
| stats values(app) as app first(views_7d) as views_7d first(edits_7d) as edits_7d first(errors_7d) as errors_7d avg(load_time_7d) as avg_load_time_7d by pretty_name \
| fillnull value=0 views_7d edits_7d errors_7d avg_load_time_7d \
| lookup caca_settings setting_name AS tmp OUTPUT setting_value AS tmp2 \
| lookup caca_settings setting_name OUTPUT setting_value \
| appendpipe [| inputlookup caca_settings | eval {setting_name}=setting_value | stats values(*) as * | eval _merge="settings"] \
| eventstats values(error_threshold_warning) as _warn_thresh values(error_threshold_critical) as _crit_thresh \
| where isnotnull(pretty_name) \
| eval health_status=case(\
    errors_7d >= coalesce(_crit_thresh, 10), "critical",\
    errors_7d >= coalesce(_warn_thresh, 1), "warning",\
    views_7d == 0, "stale",\
    1=1, "healthy") \
| fields - _warn_thresh _crit_thresh _merge
iseval = 0

# Get summary with custom time range
[get_all_dashboards_summary_timerange(1)]
args = timerange
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.*" BY pretty_name, metric_name, app span=1d \
| where _time >= relative_time(now(), "$timerange$") \
| stats sum(metric_value) as total_value by pretty_name, metric_name, app \
| eval metric_type=case(\
    metric_name=="dashboard.views", "views",\
    metric_name=="dashboard.edits", "edits",\
    metric_name=="dashboard.errors", "errors",\
    metric_name=="dashboard.load_time", "load_time",\
    1=1, "other") \
| eval {metric_type}=total_value \
| stats values(app) as app first(views) as views first(edits) as edits first(errors) as errors avg(load_time) as avg_load_time by pretty_name \
| fillnull value=0 views edits errors avg_load_time
iseval = 0

#####################
# Last Activity Tracking
#####################

# Get the last time a dashboard was viewed
[get_dashboard_last_viewed(1)]
args = dashboard_name
definition = | mstats latest(_value) as last_view WHERE index=caca_metrics AND metric_name="dashboard.views" AND pretty_name="$dashboard_name$" BY pretty_name \
| eval last_viewed=strftime(_time, "%Y-%m-%d %H:%M:%S") \
| eval days_since_view=round((now()-_time)/86400, 1) \
| eval is_stale=if(days_since_view > 30, "yes", "no")
iseval = 0

# Get all dashboards sorted by last view time
[get_dashboards_by_recency]
definition = | mstats latest(_value) as last_view WHERE index=caca_metrics AND metric_name="dashboard.views" BY pretty_name, app \
| eval last_viewed=strftime(_time, "%Y-%m-%d %H:%M:%S") \
| eval days_since_view=round((now()-_time)/86400, 1) \
| sort -_time \
| lookup dashboard_registry pretty_name OUTPUT owner sharing description
iseval = 0

#####################
# Top Performers
#####################

# Get top dashboards by a specific metric type
[get_top_dashboards(1)]
args = metric_type
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.$metric_type$" BY pretty_name, app span=1d \
| where _time >= relative_time(now(), "-7d@d") \
| stats sum(metric_value) as total by pretty_name, app \
| sort -total \
| head 10 \
| streamstats count as rank \
| eval metric_type="$metric_type$"
iseval = 0

# Get top dashboards with custom limit and timerange
[get_top_dashboards_custom(3)]
args = metric_type, limit, timerange
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.$metric_type$" BY pretty_name, app span=1d \
| where _time >= relative_time(now(), "$timerange$") \
| stats sum(metric_value) as total by pretty_name, app \
| sort -total \
| head $limit$ \
| streamstats count as rank \
| eval metric_type="$metric_type$"
iseval = 0

#####################
# Performance Analysis
#####################

# Get performance metrics for a specific dashboard
[get_dashboard_performance(1)]
args = dashboard_name
definition = | mstats avg(_value) as avg_load_time max(_value) as max_load_time min(_value) as min_load_time WHERE index=caca_metrics AND metric_name="dashboard.load_time" AND pretty_name="$dashboard_name$" BY pretty_name span=1h \
| stats avg(avg_load_time) as avg_load_time max(max_load_time) as max_load_time min(min_load_time) as min_load_time by pretty_name \
| eval avg_load_time=round(avg_load_time, 2) \
| eval max_load_time=round(max_load_time, 2) \
| eval min_load_time=round(min_load_time, 2) \
| eval performance_rating=case(\
    avg_load_time < 1000, "Excellent",\
    avg_load_time < 3000, "Good",\
    avg_load_time < 5000, "Fair",\
    avg_load_time < 10000, "Poor",\
    1=1, "Critical")
iseval = 0

# Get all slow dashboards
[get_slow_dashboards]
definition = | mstats avg(_value) as avg_load_time WHERE index=caca_metrics AND metric_name="dashboard.load_time" BY pretty_name, app span=1d \
| where _time >= relative_time(now(), "-7d@d") \
| stats avg(avg_load_time) as avg_load_time_7d by pretty_name, app \
| where avg_load_time_7d > 3000 \
| eval avg_load_time_7d=round(avg_load_time_7d, 0) \
| eval performance_status=case(\
    avg_load_time_7d > 10000, "Critical",\
    avg_load_time_7d > 5000, "Poor",\
    avg_load_time_7d > 3000, "Fair",\
    1=1, "Good") \
| sort -avg_load_time_7d \
| lookup dashboard_registry pretty_name OUTPUT owner description
iseval = 0

# Get slow dashboards with custom threshold
[get_slow_dashboards_threshold(1)]
args = threshold_ms
definition = | mstats avg(_value) as avg_load_time WHERE index=caca_metrics AND metric_name="dashboard.load_time" BY pretty_name, app span=1d \
| where _time >= relative_time(now(), "-7d@d") \
| stats avg(avg_load_time) as avg_load_time_7d by pretty_name, app \
| where avg_load_time_7d > $threshold_ms$ \
| eval avg_load_time_7d=round(avg_load_time_7d, 0) \
| sort -avg_load_time_7d \
| lookup dashboard_registry pretty_name OUTPUT owner description
iseval = 0

#####################
# Health & Error Analysis
#####################

# Get dashboards with errors
[get_dashboards_with_errors]
definition = | mstats sum(_value) as error_count WHERE index=caca_metrics AND metric_name="dashboard.errors" BY pretty_name, severity, app span=1d \
| where _time >= relative_time(now(), "-7d@d") \
| stats sum(error_count) as total_errors by pretty_name, severity, app \
| eval {severity}=total_errors \
| stats sum(error) as errors sum(warn) as warnings sum(total_errors) as total_issues by pretty_name, app \
| fillnull value=0 errors warnings total_issues \
| where total_issues > 0 \
| eval health_status=case(\
    errors > 50, "Critical",\
    errors > 10, "High",\
    errors > 0, "Medium",\
    warnings > 20, "Medium",\
    1=1, "Low") \
| sort -errors -warnings \
| lookup dashboard_registry pretty_name OUTPUT owner description
iseval = 0

# Get problematic dashboards combining health and performance issues
[get_problematic_dashboards]
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.*" BY pretty_name, metric_name, app span=1d \
| where _time >= relative_time(now(), "-7d@d") \
| stats sum(metric_value) as total_value by pretty_name, metric_name, app \
| eval metric_type=case(\
    metric_name=="dashboard.views", "views_7d",\
    metric_name=="dashboard.edits", "edits_7d",\
    metric_name=="dashboard.errors", "errors_7d",\
    metric_name=="dashboard.load_time", "load_time_7d",\
    1=1, "other") \
| eval {metric_type}=total_value \
| stats values(app) as app first(views_7d) as views_7d first(edits_7d) as edits_7d first(errors_7d) as errors_7d avg(load_time_7d) as avg_load_time_7d by pretty_name \
| fillnull value=0 views_7d edits_7d errors_7d avg_load_time_7d \
| eval health_status=case(\
    errors_7d > 10, "critical",\
    errors_7d > 0, "warning",\
    views_7d == 0, "stale",\
    1=1, "healthy") \
| where health_status="critical" OR health_status="warning" OR avg_load_time_7d > 5000 \
| eval issue_type=case(\
    health_status="critical" AND avg_load_time_7d > 5000, "Health + Performance",\
    health_status="critical", "Health Critical",\
    health_status="warning" AND avg_load_time_7d > 5000, "Health + Performance",\
    health_status="warning", "Health Warning",\
    avg_load_time_7d > 5000, "Performance",\
    1=1, "Other") \
| table pretty_name app views_7d errors_7d avg_load_time_7d health_status issue_type \
| sort -errors_7d -avg_load_time_7d \
| lookup dashboard_registry pretty_name OUTPUT owner description
iseval = 0

#####################
# Stale Content Detection
#####################

# Get stale dashboards (not viewed in X days)
[get_stale_dashboards(1)]
args = days_threshold
definition = | inputlookup dashboard_registry \
| join type=left pretty_name \
    [| mstats latest(_value) as last_view WHERE index=caca_metrics AND metric_name="dashboard.views" BY pretty_name \
    | eval last_viewed_time=_time \
    | eval days_since_view=round((now()-_time)/86400, 1)] \
| eval days_since_view=if(isnull(days_since_view), 999, days_since_view) \
| where days_since_view > $days_threshold$ \
| eval last_viewed=if(days_since_view==999, "Never", strftime(last_viewed_time, "%Y-%m-%d")) \
| eval staleness=case(\
    days_since_view==999, "Never Viewed",\
    days_since_view > 365, "Ancient (1+ year)",\
    days_since_view > 180, "Very Stale (6+ months)",\
    days_since_view > 90, "Stale (3+ months)",\
    1=1, "Cooling") \
| sort -days_since_view
iseval = 0

# Get ghost dashboards (never viewed)
[get_ghost_dashboards]
definition = | inputlookup dashboard_registry \
| join type=left pretty_name \
    [| mstats latest(_value) as last_view WHERE index=caca_metrics AND metric_name="dashboard.views" BY pretty_name] \
| where isnull(last_view) \
| table pretty_name app owner sharing description status
iseval = 0

#####################
# Engagement & Value Analysis
#####################

# Calculate engagement score for dashboards
[get_dashboard_engagement_scores]
definition = | mstats sum(_value) as metric_value WHERE index=caca_metrics AND metric_name="dashboard.*" BY pretty_name, metric_name, app span=1d \
| where _time >= relative_time(now(), "-30d@d") \
| stats sum(metric_value) as total by pretty_name, metric_name, app \
| eval metric_type=case(\
    metric_name=="dashboard.views", "views",\
    metric_name=="dashboard.edits", "edits",\
    metric_name=="dashboard.errors", "errors",\
    1=1, "other") \
| eval {metric_type}=total \
| stats values(app) as app first(views) as views_30d first(edits) as edits_30d first(errors) as errors_30d by pretty_name \
| fillnull value=0 views_30d edits_30d errors_30d \
| eval engagement_score=views_30d + (edits_30d * 2) - (errors_30d * 5) \
| eval engagement_score=if(engagement_score < 0, 0, engagement_score) \
| sort -engagement_score \
| lookup dashboard_registry pretty_name OUTPUT owner description
iseval = 0

# Get VIP dashboards (top percentile by views)
[get_vip_dashboards(1)]
args = percentile
definition = | mstats sum(_value) as total_views WHERE index=caca_metrics AND metric_name="dashboard.views" BY pretty_name, app span=1d \
| where _time >= relative_time(now(), "-30d@d") \
| stats sum(total_views) as views_30d by pretty_name, app \
| eventstats perc$percentile$(views_30d) as threshold \
| where views_30d >= threshold \
| sort -views_30d \
| lookup dashboard_registry pretty_name OUTPUT owner description
iseval = 0

#####################
# Filtering Macros
#####################

# Filter results by app using the app_filter lookup
[filter_by_app]
definition = | lookup app_filter app OUTPUT include \
| where isnull(include) OR include="true" OR include="1" OR include="yes" \
| fields - include
iseval = 0

# Filter results to exclude system/internal apps
[filter_system_apps]
definition = | where NOT match(app, "^(splunk_|_|system|search|launcher|learned|alert_logevent|alert_webhook|appsbrowser|introspection_generator|legacy|sample_app|SplunkForwarder)")
iseval = 0

#####################
# Utility Macros
#####################

# Index definition for CACA metrics
[caca_metrics_index]
definition = index=caca_metrics
iseval = 0

# Standard time spans for metrics queries
[caca_default_span]
definition = span=1h
iseval = 0

# Format load time for display
[format_load_time(1)]
args = field_name
definition = | eval $field_name$_display=case(\
    $field_name$ < 1000, round($field_name$, 0)." ms",\
    $field_name$ < 60000, round($field_name$/1000, 1)." s",\
    1=1, round($field_name$/60000, 1)." min")
iseval = 0

# Calculate health badge based on metrics
[calculate_health_badge]
definition = | eval health_badge=case(\
    health_status=="healthy", "Healthy",\
    health_status=="warning", "Warning",\
    health_status=="critical", "Critical",\
    health_status=="stale", "Stale",\
    1=1, health_status)
iseval = 0

# Calculate performance rating
[calculate_perf_rating]
definition = | eval perf_rating=case(\
    avg_load_time == 0 OR isnull(avg_load_time), "-",\
    avg_load_time < 1000, "Fast",\
    avg_load_time < 3000, "Good",\
    avg_load_time < 5000, "Slow",\
    1=1, "Very Slow")
iseval = 0
